{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN2SUDq/46yUBPvz7yOfeFI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rylan-berry/DeepLearningIndependentStudy/blob/main/Chapter9ProblemSet_RylanBerry.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bf46acb3"
      },
      "source": [
        "# Task\n",
        "The task is to explore Convolutional Neural Networks (CNNs) by answering conceptual questions, implementing core operations like 2D convolution and pooling from scratch, building and training a simple CNN model on a standard image dataset, visualizing feature maps, and summarizing the findings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73a76659"
      },
      "source": [
        "## Conceptual Questions on CNNs\n",
        "\n",
        "### Subtask:\n",
        "Formulate a set of conceptual questions covering fundamental aspects of Convolutional Networks, such as the convolution operation, padding, stride, pooling layers (max and average), activation functions, feature maps, and the benefits of CNNs for image processing, drawing from Chapter 9 of the Deep Learning book and the provided video.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ee0ea1c4"
      },
      "source": [
        "## Conceptual Questions on CNNs\n",
        "\n",
        "1.  **What is the convolution operation in the context of CNNs, and what is its primary purpose?**\n",
        "\n",
        "     - *The convolution operation takes two functions (matricis in our case) and does element wise multiplication and then summation of those for each case where function two fits in function 1. The purpose is to slowly inform each section of the closest other functions. For example, nearby pixels will try to inform about itself based on the neighbhoring pixels primarily.*\n",
        "\n",
        "2.  **Explain the role of padding in a convolutional layer. Name two common types of padding and when they might be used.**\n",
        "\n",
        "    - *Adding extra information to a dataset to make it fit the input (commonly just filled with zeros). It can also serve to keep edge information that would typically only get a few convolutions, but with padding it get's to contribute longer.*\n",
        "    - *SAME Padding (Zero Padding): Add padding to an image after a convolution to maintain the same size as the input.*\n",
        "    - *VALID Padding (No Padding): Only takes in the ammount of inputs a layer allows (if an input is too large and needs to be cut down). Dims are smaller after this operation. Ofc used to reduce the size of an image, but can also be used if you want the model to focus on specific features and throw out boundry data.*\n",
        "\n",
        "3.  **How does stride affect the output dimensions of a convolutional layer?**\n",
        "\n",
        "    - *It reduces the size since stride determines how many steps each kernel move takes. So increasing it means greater step size and less operations. And less operations means less numbers outputted.*\n",
        "\n",
        "4.  **Compare and contrast Max Pooling and Average Pooling layers. What is the main purpose of pooling layers in general?**\n",
        "\n",
        "    - *Pooling goes through an area and decides a value for that area (can overlap like the convolution opperation). Max pooling takes the highest value of that section and outputs it, while Average pooling takes the average of the area.*\n",
        "\n",
        "5.  **Identify a common activation function used in CNNs and describe its role.**\n",
        "\n",
        "    - *Rectified Linear Unit (ReLU) is common for CNNs. It introduces nonlinearity and is simple (and avoids gradient problems since it's either 0 or 1).*\n",
        "\n",
        "6.  **What do feature maps represent in a CNN?**\n",
        "    - *Feature maps is an overlay for an image, with each pixel getting a percentage on the expectation of what feature it is. And applied across an entire image, a model should be able to decide what in an image is what.*\n",
        "\n",
        "7.  **What are the key benefits of using CNNs for image processing compared to traditional neural networks (e.g., fully connected networks)?**\n",
        "    - *This is much simpiler, there are less operations since not all of the inputs effect all of the other inputs, it really only focuses on the neighbors, making CNNs faster to compute. And the architecture is based on how eyes actually identify things, which is pretty cool!!*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c05e4257"
      },
      "source": [
        "## Implement 2D Convolution Operation\n",
        "\n",
        "### Subtask:\n",
        "Implement a 2D convolution operation from scratch using libraries like NumPy, including options for padding and stride. This step should involve generating example input data and a kernel, then applying the convolution.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f061658f",
        "outputId": "91c0eaea-69cc-481c-83a6-9958a50826b4"
      },
      "source": [
        "import numpy as np\n",
        "print(\"NumPy imported successfully.\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NumPy imported successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from math import ceil"
      ],
      "metadata": {
        "id": "PuQfJT39Y3gZ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5f7e9a9a",
        "outputId": "d0acadb4-0350-48ee-e317-9d5adc52b527"
      },
      "source": [
        "from math import ceil\n",
        "\n",
        "def convolve2d(input_matrix, kernel_matrix, padding='valid', stride=1):\n",
        "    input_height, input_width = input_matrix.shape\n",
        "    kernel_height, kernel_width = kernel_matrix.shape\n",
        "\n",
        "    pad_top, pad_bottom, pad_left, pad_right = 0, 0, 0, 0\n",
        "\n",
        "    if padding == 'same':\n",
        "        # Calculate output dimensions based on 'same' padding logic:\n",
        "        # output_dim = ceil(input_dim / stride)\n",
        "        # This is a common interpretation in frameworks like TensorFlow/Keras\n",
        "        output_height_target = ceil(input_height / stride)\n",
        "        output_width_target = ceil(input_width / stride)\n",
        "\n",
        "        # Calculate total padding needed to achieve the target output dimensions\n",
        "        total_padding_h = max(0, (output_height_target - 1) * stride + kernel_height - input_height)\n",
        "        total_padding_w = max(0, (output_width_target - 1) * stride + kernel_width - input_width)\n",
        "\n",
        "        # Distribute padding to top/bottom and left/right. If padding is odd, more goes to bottom/right.\n",
        "        pad_top = total_padding_h // 2\n",
        "        pad_bottom = total_padding_h - pad_top\n",
        "        pad_left = total_padding_w // 2\n",
        "        pad_right = total_padding_w - pad_left\n",
        "    elif padding != 'valid':\n",
        "        print(\"ERROR: Padding method does not exist\")\n",
        "        return None\n",
        "\n",
        "    # Apply padding to the input matrix\n",
        "    padded_input = np.pad(input_matrix, ((pad_top, pad_bottom), (pad_left, pad_right)), mode='constant')\n",
        "\n",
        "    # Calculate the actual output dimensions after padding and considering stride\n",
        "    # Formula: (Padded_Input_Dimension - Kernel_Dimension) // Stride + 1\n",
        "    output_height = (padded_input.shape[0] - kernel_height) // stride + 1\n",
        "    output_width = (padded_input.shape[1] - kernel_width) // stride + 1\n",
        "\n",
        "    # Initialize the output matrix with zeros\n",
        "    output_matrix = np.zeros((output_height, output_width))\n",
        "\n",
        "    # Perform the convolution operation\n",
        "    for i in range(output_height):\n",
        "        for j in range(output_width):\n",
        "            # Extract the current window (receptive field) from the padded input\n",
        "            window = padded_input[i * stride : i * stride + kernel_height,\n",
        "                                  j * stride : j * stride + kernel_width]\n",
        "\n",
        "            # Perform element-wise multiplication and sum (dot product)\n",
        "            output_matrix[i, j] = np.sum(window * kernel_matrix)\n",
        "\n",
        "    return output_matrix\n",
        "\n",
        "print(\"convolve2d function defined.\")\n",
        "\n",
        "# Generate sample input data and a kernel\n",
        "input_data = np.array([\n",
        "    [1, 1, 1, 0, 0],\n",
        "    [0, 1, 1, 1, 0],\n",
        "    [0, 0, 1, 1, 1],\n",
        "    [0, 0, 1, 1, 0],\n",
        "    [0, 1, 1, 0, 0]\n",
        "])\n",
        "\n",
        "kernel = np.array([\n",
        "    [1, 0, 1],\n",
        "    [0, 1, 0],\n",
        "    [1, 0, 1]\n",
        "])\n",
        "\n",
        "print(\"\\nSample Input Data:\\n\", input_data)\n",
        "print(\"\\nSample Kernel:\\n\", kernel)\n",
        "\n",
        "# Experiment with different padding and stride values\n",
        "print(\"\\n--- Experimenting with different parameters ---\")\n",
        "\n",
        "# 1. 'valid' padding, stride 1\n",
        "# Expected output height: (5 - 3) // 1 + 1 = 3\n",
        "# Expected output width: (5 - 3) // 1 + 1 = 3\n",
        "output_valid_stride1 = convolve2d(input_data, kernel, padding='valid', stride=1)\n",
        "print(\"\\nOutput (padding='valid', stride=1):\\n\", output_valid_stride1)\n",
        "\n",
        "# 2. 'same' padding, stride 1\n",
        "# Expected output height: ceil(5/1) = 5\n",
        "# Expected output width: ceil(5/1) = 5\n",
        "output_same_stride1 = convolve2d(input_data, kernel, padding='same', stride=1)\n",
        "print(\"\\nOutput (padding='same', stride=1):\\n\", output_same_stride1)\n",
        "\n",
        "# 3. 'valid' padding, stride 2\n",
        "# Expected output height: (5 - 3) // 2 + 1 = 2\n",
        "# Expected output width: (5 - 3) // 2 + 1 = 2\n",
        "output_valid_stride2 = convolve2d(input_data, kernel, padding='valid', stride=2)\n",
        "print(\"\\nOutput (padding='valid', stride=2):\\n\", output_valid_stride2)\n",
        "\n",
        "# 4. 'same' padding, stride 2\n",
        "# Expected output height: ceil(5/2) = 3\n",
        "# Expected output width: ceil(5/2) = 3\n",
        "output_same_stride2 = convolve2d(input_data, kernel, padding='same', stride=2)\n",
        "print(\"\\nOutput (padding='same', stride=2):\\n\", output_same_stride2)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "convolve2d function defined.\n",
            "\n",
            "Sample Input Data:\n",
            " [[1 1 1 0 0]\n",
            " [0 1 1 1 0]\n",
            " [0 0 1 1 1]\n",
            " [0 0 1 1 0]\n",
            " [0 1 1 0 0]]\n",
            "\n",
            "Sample Kernel:\n",
            " [[1 0 1]\n",
            " [0 1 0]\n",
            " [1 0 1]]\n",
            "\n",
            "--- Experimenting with different parameters ---\n",
            "\n",
            "Output (padding='valid', stride=1):\n",
            " [[4. 3. 4.]\n",
            " [2. 4. 3.]\n",
            " [2. 3. 4.]]\n",
            "\n",
            "Output (padding='same', stride=1):\n",
            " [[2. 2. 3. 1. 1.]\n",
            " [1. 4. 3. 4. 1.]\n",
            " [1. 2. 4. 3. 3.]\n",
            " [1. 2. 3. 4. 1.]\n",
            " [0. 2. 2. 1. 1.]]\n",
            "\n",
            "Output (padding='valid', stride=2):\n",
            " [[4. 4.]\n",
            " [2. 4.]]\n",
            "\n",
            "Output (padding='same', stride=2):\n",
            " [[2. 3. 1.]\n",
            " [1. 4. 3.]\n",
            " [0. 2. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39ae559f"
      },
      "source": [
        "## Implement Pooling Layers\n",
        "\n",
        "### Subtask:\n",
        "Implement Max Pooling and Average Pooling layers from scratch. Provide example input data and demonstrate how these layers reduce spatial dimensions.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6624d0d9",
        "outputId": "e9e7ae10-43d6-4cc5-b45f-d3d21109345d"
      },
      "source": [
        "def max_pooling(input_matrix, pool_size, stride=None):\n",
        "  in_h, in_w = input_matrix.shape\n",
        "  p_h, p_w = pool_size\n",
        "  if stride == None:\n",
        "    stride = 1\n",
        "  output_height = (in_h - p_h) // stride + 1\n",
        "  output_width = (in_w - p_w) // stride + 1\n",
        "  out = np.zeros((output_height, output_width))\n",
        "  for i in range(output_height):\n",
        "    for j in range(output_width):\n",
        "      window = input_matrix[i*stride : i*stride+p_h, j*stride : j*stride+p_w]\n",
        "      out[i][j] = np.max(window)\n",
        "  return out\n",
        "\n",
        "\n",
        "print(\"max_pooling function defined.\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_pooling function defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75f8dd72",
        "outputId": "8b6fceb6-30e5-401d-8f16-d0feb2fffd65"
      },
      "source": [
        "def average_pooling(input_matrix, pool_size, stride=None):\n",
        "  in_h, in_w = input_matrix.shape\n",
        "  p_h, p_w = pool_size\n",
        "  if stride == None:\n",
        "    stride = 1\n",
        "  output_height = (in_h - p_h) // stride + 1\n",
        "  output_width = (in_w - p_w) // stride + 1\n",
        "  out = np.zeros((output_height, output_width))\n",
        "  for i in range(output_height):\n",
        "    for j in range(output_width):\n",
        "      window = input_matrix[i*stride : i*stride+p_h, j*stride : j*stride+p_w]\n",
        "      out[i][j] = np.mean(window)\n",
        "  return out\n",
        "\n",
        "print(\"average_pooling function defined.\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average_pooling function defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e818e63e",
        "outputId": "407b2e74-a896-4468-bc29-e936305ff6a3"
      },
      "source": [
        "print(\"\\n--- Demonstrating Pooling Operations ---\")\n",
        "\n",
        "# Generate a sample input matrix\n",
        "pooling_input_data = np.array([\n",
        "    [1, 2, 3, 4],\n",
        "    [5, 6, 7, 8],\n",
        "    [9, 10, 11, 12],\n",
        "    [13, 14, 15, 16]\n",
        "])\n",
        "pool_size = (2, 2)\n",
        "\n",
        "print(\"\\nOriginal Input Data for Pooling:\\n\", pooling_input_data)\n",
        "print(\"Pool Size:\", pool_size)\n",
        "\n",
        "# Apply Max Pooling\n",
        "max_pooled_output = max_pooling(pooling_input_data, pool_size)\n",
        "print(\"\\nMax Pooled Output:\\n\", max_pooled_output)\n",
        "\n",
        "# Apply Average Pooling\n",
        "average_pooled_output = average_pooling(pooling_input_data, pool_size)\n",
        "print(\"\\nAverage Pooled Output:\\n\", average_pooled_output)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Demonstrating Pooling Operations ---\n",
            "\n",
            "Original Input Data for Pooling:\n",
            " [[ 1  2  3  4]\n",
            " [ 5  6  7  8]\n",
            " [ 9 10 11 12]\n",
            " [13 14 15 16]]\n",
            "Pool Size: (2, 2)\n",
            "\n",
            "Max Pooled Output:\n",
            " [[ 6.  7.  8.]\n",
            " [10. 11. 12.]\n",
            " [14. 15. 16.]]\n",
            "\n",
            "Average Pooled Output:\n",
            " [[ 3.5  4.5  5.5]\n",
            " [ 7.5  8.5  9.5]\n",
            " [11.5 12.5 13.5]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19fc901c"
      },
      "source": [
        "## Build a Simple CNN Model\n",
        "\n",
        "Implement CNNs into the NN package and make a new MNIST model. Include a flatten layer to move the CNNs 2d shape to 1d. Use the sample from the answer key version as a basis for model inspiration."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c11efc10",
        "outputId": "96f62562-0aaf-45c4-9fe4-1178dd02cb6e"
      },
      "source": [
        "!pip install rb-deeplearning-lib==0.2.9\n",
        "import rb_deeplearning_lib"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rb-deeplearning-lib==0.2.9\n",
            "  Downloading rb_deeplearning_lib-0.2.9-py3-none-any.whl.metadata (8.8 kB)\n",
            "Requirement already satisfied: numpy>=2.0 in /usr/local/lib/python3.12/dist-packages (from rb-deeplearning-lib==0.2.9) (2.0.2)\n",
            "Downloading rb_deeplearning_lib-0.2.9-py3-none-any.whl (13 kB)\n",
            "Installing collected packages: rb-deeplearning-lib\n",
            "  Attempting uninstall: rb-deeplearning-lib\n",
            "    Found existing installation: rb-deeplearning-lib 0.2.8\n",
            "    Uninstalling rb-deeplearning-lib-0.2.8:\n",
            "      Successfully uninstalled rb-deeplearning-lib-0.2.8\n",
            "Successfully installed rb-deeplearning-lib-0.2.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from rb_deeplearning_lib import Model, mse_loss"
      ],
      "metadata": {
        "id": "-1yZprBJFNTL"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from rb_deeplearning_lib import Convo2D"
      ],
      "metadata": {
        "id": "uuyrwwRyGh-U"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kernel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RX2HtzHhniLY",
        "outputId": "18341074-391c-45ed-9030-aab7787a1cfb"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 0, 1],\n",
              "       [0, 1, 0],\n",
              "       [1, 0, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Mwp5jjSnjIQ",
        "outputId": "4c29694c-3430-4794-ac54-c91394ba285d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 1, 1, 0, 0],\n",
              "       [0, 1, 1, 1, 0],\n",
              "       [0, 0, 1, 1, 1],\n",
              "       [0, 0, 1, 1, 0],\n",
              "       [0, 1, 1, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conTest = Convo2D(kernel,padding='same',stride=2) #using default padding and stride\n",
        "conTest.params()[0].vals"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXhQjmDJm45I",
        "outputId": "f491c960-2120-457e-ae84-e59db386e131"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conTest(input_data) == output_same_stride2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMnuj5_knnuv",
        "outputId": "448b154f-3289-4b01-9dd8-7dc18e3415d4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[ True,  True,  True],\n",
              "        [ True,  True,  True],\n",
              "        [ True,  True,  True]]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pooling_input_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWqzfznMoPYn",
        "outputId": "30133ccc-f2cc-42d1-c9bf-58ce9f8bff8a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1,  2,  3,  4],\n",
              "       [ 5,  6,  7,  8],\n",
              "       [ 9, 10, 11, 12],\n",
              "       [13, 14, 15, 16]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pool_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rpzx_Xd4oS0k",
        "outputId": "e2dc5353-97ba-4f20-83e0-5d28dbbd7ba7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "poolTest = MaxPooling(pool_size) #using default stride"
      ],
      "metadata": {
        "id": "RvyWQI8Pn8pg"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "poolTest(pooling_input_data) == max_pooled_output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfjKLMl0pr9p",
        "outputId": "52bcf7c2-1212-447c-b5f5-3dc90dfecfca"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[ True,  True,  True],\n",
              "        [ True,  True,  True],\n",
              "        [ True,  True,  True]]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "poolTest2 = AvgPooling(pool_size) #using default stride"
      ],
      "metadata": {
        "id": "C6idKdzBrL0R"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "poolTest2(pooling_input_data) == average_pooled_output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "caIdPkvprQQJ",
        "outputId": "d1f6cadb-baec-46a6-9a66-eaaebbf888ee"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[ True,  True,  True],\n",
              "        [ True,  True,  True],\n",
              "        [ True,  True,  True]]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kernel.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9M8MWg_UpFk3",
        "outputId": "9a329dc7-5da7-4b0b-8df0-fcf7616caea4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m = Model([Convo2D(kernel),MaxPooling(pool_size)],loss_fn=mse_loss)\n"
      ],
      "metadata": {
        "id": "lsf-otyvAOvu"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = np.random.rand(10, 5, 5) # 10 samples, each 5x5 image\n",
        "y_train = np.random.randint(0, 2, (10,2,2)) # 10 labels (binary classification example)\n",
        "\n",
        "x_val = np.random.rand(2, 5, 5) # 2 validation samples, each 5x5 image\n",
        "y_val = np.random.randint(0, 2, (2,2,2)) # 2 validation labels"
      ],
      "metadata": {
        "id": "qHwoQ7uNA-dl"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IbXgo1acBz4d",
        "outputId": "eaa74bf2-e838-401b-bb14-ca9c75ba240b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 2, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_val.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1msNsEEfBz8E",
        "outputId": "f8f275bf-5ec1-4bd5-d032-0bcd2ef43282"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 2, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m(x_train).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFbyxfoZBOBE",
        "outputId": "541026c8-fec1-4442-f238-96dd4e06e31b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 2, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m(x_val).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvy47Oh5Bi2t",
        "outputId": "c3b614cb-d770-48e0-98c7-d0da6e0ae5ca"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 2, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m.train(20, x_train, y_train, x_val, y_val, batch_size=1)\n",
        "\n",
        "#Ok, maybe not a backprop issue, but an update issue. Regular optim works on other NN models but not here, likely an issue with params"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2RREtkZBVM9",
        "outputId": "f4486dc8-afad-41fd-cc00-95b95b369d1b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0 \t loss: 34.68726232446199\n",
            "\rep0: b0/10\rep0: b1/10\rep0: b2/10\rep0: b3/10\rep0: b4/10\rep0: b5/10\rep0: b6/10\rep0: b7/10\rep0: b8/10\rep0: b9/10\repoch: 1 \t loss: 0.27791138066704774\n",
            "epoch: 2 \t loss: 1.1705174391047195\n",
            "epoch: 3 \t loss: 0.5984476946135048\n",
            "epoch: 4 \t loss: 0.7314372662331357\n",
            "epoch: 5 \t loss: 0.3676912589457245\n",
            "epoch: 6 \t loss: 0.3478450964378932\n",
            "epoch: 7 \t loss: 0.5546801397186385\n",
            "epoch: 8 \t loss: 1.012329095422709\n",
            "epoch: 9 \t loss: 0.5979963242352069\n",
            "epoch: 10 \t loss: 1.128466386792609\n",
            "epoch: 11 \t loss: 0.6179974795546153\n",
            "epoch: 12 \t loss: 0.7052842574186196\n",
            "epoch: 13 \t loss: 0.7002898687592528\n",
            "epoch: 14 \t loss: 0.8524257311404697\n",
            "epoch: 15 \t loss: 0.4696200677217798\n",
            "epoch: 16 \t loss: 0.7299302468499798\n",
            "epoch: 17 \t loss: 0.631450615565303\n",
            "epoch: 18 \t loss: 0.831587707647354\n",
            "epoch: 19 \t loss: 0.37690052391472284\n",
            "epoch: 20 \t loss: 0.7429505358522794\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from rb_deeplearning_lib import Model, mse_loss\n",
        "\n",
        "# Re-initialize the model (Convo2D and MaxPooling are already defined in previous cells)\n",
        "m = Model([Convo2D(kernel), MaxPooling(pool_size)], loss_fn=mse_loss)\n",
        "\n",
        "# Re-initialize training data for a fresh start\n",
        "x_train = np.random.rand(10, 5, 5) # 10 samples, each 5x5 image\n",
        "y_train = np.random.randint(0, 2, 10) # 10 labels (binary classification example)\n",
        "\n",
        "print(\"Model and data re-initialized.\")\n",
        "\n",
        "# 1. Perform a single forward pass with a small batch\n",
        "# Get a single input and its corresponding target\n",
        "input_batch = Values(x_train[0:1]) # Wrap input in Values object\n",
        "target_batch = Values(np.array([y_train[0:1]]).astype(float)) # Wrap target in Values object, ensure float type\n",
        "\n",
        "# Perform forward pass\n",
        "output = m(input_batch)\n",
        "\n",
        "# Calculate loss using the model's loss_fn\n",
        "loss = m.loss_fn(output, target_batch)\n",
        "\n",
        "print(f\"\\nInitial loss after one forward pass: {loss.vals}\")\n",
        "\n",
        "# 2. Call loss.backward() to compute gradients\n",
        "loss.backward()\n",
        "print(\"Backward pass completed.\")\n",
        "\n",
        "# 3. Inspect the gradient of the Convo2D layer's kernel\n",
        "conv_kernel_grad = m.blocks.arr[0].kernel.grad\n",
        "\n",
        "print(\"\\n--- Convo2D Kernel Gradient Inspection ---\")\n",
        "print(f\"Shape of Convo2D kernel gradient: {conv_kernel_grad.shape}\")\n",
        "print(f\"Max value of Convo2D kernel gradient: {np.max(conv_kernel_grad)}\")\n",
        "print(f\"Min value of Convo2D kernel gradient: {np.min(conv_kernel_grad)}\")\n",
        "print(f\"Mean value of Convo2D kernel gradient: {np.mean(conv_kernel_grad)}\")\n",
        "\n",
        "print(f\"Convo2D Params: {m.blocks.arr[0].params()}\")\n",
        "print(f\"Seq Params: {m.blocks.params()}\")\n",
        "\n",
        "# Inspect gradients of other layers if any\n",
        "# In this simple model, only the Convo2D layer has learnable parameters (the kernel).\n",
        "# The MaxPooling layer does not have learnable parameters, so no grad to inspect directly.\n"
      ],
      "metadata": {
        "id": "1jDesYMBLhrS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec9cb566-065b-4f06-9d19-b12e256a556b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model and data re-initialized.\n",
            "\n",
            "Initial loss after one forward pass: 3.1213152097116525\n",
            "Backward pass completed.\n",
            "\n",
            "--- Convo2D Kernel Gradient Inspection ---\n",
            "Shape of Convo2D kernel gradient: (1, 3, 3)\n",
            "Max value of Convo2D kernel gradient: 27.27228882384024\n",
            "Min value of Convo2D kernel gradient: 0.7873614957679098\n",
            "Mean value of Convo2D kernel gradient: 13.946390005474433\n",
            "Convo2D Params: vals: array([[1, 0, 1],\n",
            "       [0, 1, 0],\n",
            "       [1, 0, 1]])\n",
            "grads: array([[[27.27228882,  0.7873615 , 23.06911026],\n",
            "        [ 6.74720045,  7.84812259, 24.73351547],\n",
            "        [13.80482566,  9.41239693, 11.84268837]]])\n",
            "Seq Params: [vals: array([[1, 0, 1],\n",
            "       [0, 1, 0],\n",
            "       [1, 0, 1]])\n",
            "grads: array([[[27.27228882,  0.7873615 , 23.06911026],\n",
            "        [ 6.74720045,  7.84812259, 24.73351547],\n",
            "        [13.80482566,  9.41239693, 11.84268837]]])]\n"
          ]
        }
      ]
    }
  ]
}